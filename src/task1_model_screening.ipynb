{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n",
    "\n",
    "The dataset used in this example is the 20 newsgroups dataset. It will be\n",
    "automatically downloaded, then cached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration options for the analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, we use `HashingVectorizer`, otherwise we use a `TfidfVectorizer`\n",
    "USE_HASHING = False\n",
    "\n",
    "# Number of features used by `HashingVectorizer`\n",
    "N_FEATURES = 2**16\n",
    "\n",
    "# Optional feature selection: either False, or an integer: the number of\n",
    "# features to select\n",
    "SELECT_CHI2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the training set\n",
    "Let's load data from the newsgroups dataset which comprises around 18000\n",
    "newsgroups posts on 20 topics split in two subsets: one for training (or\n",
    "development) and the other one for testing (or for performance evaluation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12098 documents - 0.408MB (training set)\n",
      "3025 documents - 0.102MB (test set)\n",
      "21 categories\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = [\n",
    "    '11-1021.00',\n",
    "    '11-2021.00',\n",
    "    '11-2022.00',\n",
    "    '11-3031.02',\n",
    "    '13-1111.00',\n",
    "    '13-2051.00',\n",
    "    '15-1121.00',\n",
    "    '15-1122.00',\n",
    "    '15-1132.00',\n",
    "    '15-1133.00',\n",
    "    '15-1134.00',\n",
    "    '15-1142.00',\n",
    "    '15-1151.00',\n",
    "    '29-1141.00',\n",
    "    '31-1014.00',\n",
    "    '33-3021.06',\n",
    "    '41-2031.00',\n",
    "    '43-4051.00',\n",
    "    '49-3023.02',\n",
    "    '49-9071.00',\n",
    "    '53-3032.00'\n",
    "]\n",
    "\n",
    "data_train = pd.read_csv('../data/train_df.csv')\n",
    "data_test = pd.read_csv('../data/test_df.csv')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = categories\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode(\"utf-8\")) for s in docs) / 1e6\n",
    "\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.Title)\n",
    "data_test_size_mb = size_mb(data_test.Title)\n",
    "\n",
    "print(\n",
    "    \"%d documents - %0.3fMB (training set)\" % (len(data_train.Title), data_train_size_mb)\n",
    ")\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (len(data_test.Title), data_test_size_mb))\n",
    "print(\"%d categories\" % len(target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the training and test data\n",
    "\n",
    "split a training set and a test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = data_train.Code, data_test.Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features from the training data using a sparse vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.094833s at 4.298MB/s\n",
      "n_samples: 12098, n_features: 4229\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "if USE_HASHING:\n",
    "    vectorizer = HashingVectorizer(\n",
    "        stop_words=\"english\", alternate_sign=False, n_features=N_FEATURES\n",
    "    )\n",
    "    X_train = vectorizer.transform(data_train.Title)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=\"english\")\n",
    "    X_train = vectorizer.fit_transform(data_train.Title)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features from the test data using the same vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.024329s at 4.211MB/s\n",
      "n_samples: 3025, n_features: 4229\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.Title)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping from integer feature name to original token string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HASHING:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only the best features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "if SELECT_CHI2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % SELECT_CHI2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=SELECT_CHI2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names is not None:\n",
    "        # keep selected feature names\n",
    "        feature_names = feature_names[ch2.get_support()]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark classifiers\n",
    "\n",
    "First we define small benchmarking utilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "def benchmark(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train and test the datasets with 15 different classification\n",
    "models and get performance results for each model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(solver='sag', tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/transcend/code/BANGKOK/nrich/nrich-test-assignment/venv/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:830: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.511s\n",
      "test time:  0.001s\n",
      "accuracy:   0.454\n",
      "dimensionality: 4229\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "11-1021.00: geo refurb outbound merchandiser initiative attorney ann store qp...\n",
      "11-2021.00: alliances sustainable campaign art capture channel product brand ...\n",
      "11-2022.00: underpayments immediately brands american cx pharmaceutical smb c...\n",
      "11-3031.02: vendor controller recognition outsourcing banker fc audit account...\n",
      "13-1111.00: acquistion effectiveness acquisition facets accenture mai acc loc...\n",
      "13-2051.00: reconciliation storeroom instuctor financial cont treasury budget...\n",
      "15-1121.00: fighter order lifecycle oversight ppbe maritime mss appsw linguis...\n",
      "15-1122.00: isso intrusion mcafee malware librarian fingerprinting splunk aut...\n",
      "15-1132.00: atlassian cucm netsuite hot salesforce ui tbma software trust devops\n",
      "15-1133.00: secureview ground missions gpu combat payload optical embedded da...\n",
      "15-1134.00: workers restful jbpm sofware brava osisoft rational mvc drupal sh...\n",
      "15-1142.00: iafnos ins datacenter solaris backup rqd lan engr administrator n...\n",
      "15-1151.00: disciplinary arboretum saa game tom passive desktop vip ssds desk...\n",
      "29-1141.00: eap dialysis lpn clinical hh hospital case nurse rcm rn\n",
      "31-1014.00: dietitian pbuse tbi cv patient nursing academic cardiology sleep ...\n",
      "33-3021.06: orsa target elint watchlist targeting wmd intelligence source cit...\n",
      "41-2031.00: cust decor supv sprint retail footwear cosmetics nex prestige app...\n",
      "43-4051.00: olde sched direct leasing clerical delinquency mtf rws promotions...\n",
      "49-3023.02: carpentry mini mechanic exhaust heavy automotive shop body tire lube\n",
      "49-9071.00: renovations laborer guest apartments dmv datapower roadway ammoni...\n",
      "53-3032.00: discrep weekly motor armed lst archery loom route drivers driver\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.26      0.27      0.26       147\n",
      "  11-2021.00       0.45      0.46      0.45       195\n",
      "  11-2022.00       0.40      0.34      0.37       119\n",
      "  11-3031.02       0.48      0.45      0.46       108\n",
      "  13-1111.00       0.30      0.34      0.32       173\n",
      "  13-2051.00       0.35      0.36      0.36        72\n",
      "  15-1121.00       0.31      0.18      0.23       110\n",
      "  15-1122.00       0.59      0.57      0.58       263\n",
      "  15-1132.00       0.48      0.57      0.52       270\n",
      "  15-1133.00       0.32      0.32      0.32       246\n",
      "  15-1134.00       0.44      0.22      0.30        49\n",
      "  15-1142.00       0.50      0.52      0.51       270\n",
      "  15-1151.00       0.32      0.24      0.27        89\n",
      "  29-1141.00       0.67      0.84      0.75       297\n",
      "  31-1014.00       0.37      0.19      0.25        70\n",
      "  33-3021.06       0.48      0.55      0.51       148\n",
      "  41-2031.00       0.43      0.44      0.44       109\n",
      "  43-4051.00       0.35      0.30      0.32        92\n",
      "  49-3023.02       0.41      0.43      0.42        58\n",
      "  49-9071.00       0.43      0.38      0.41        78\n",
      "  53-3032.00       0.49      0.31      0.38        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.42      0.39      0.40      3025\n",
      "weighted avg       0.45      0.45      0.45      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 39  11   2   7  14   6   2   4   5  13   0   3   0  12   1   5  10   3\n",
      "    4   3   3]\n",
      " [ 12  89  19   3  17   5   3   6  13   6   1   4   0   3   1   4   4   4\n",
      "    0   1   0]\n",
      " [  6  26  41   8   3   2   1   3   5   2   1   1   1   3   0   2   8   3\n",
      "    2   1   0]\n",
      " [  3   7   7  49  13  11   0   1   1   1   0   3   1   1   0   1   5   3\n",
      "    0   1   0]\n",
      " [ 16   9   5  10  59   4   7   5  10   9   0   9   4   8   1   7   0   5\n",
      "    3   0   2]\n",
      " [  3   1   0   7   8  26   1   7   2   6   0   1   1   3   1   3   1   0\n",
      "    1   0   0]\n",
      " [  3   3   1   0  16   4  20   7  13  14   2   6   1   4   0  14   0   0\n",
      "    0   2   0]\n",
      " [  6   7   2   5   7   0   6 149  13  18   0  21   4   2   0  11   2   3\n",
      "    5   2   0]\n",
      " [  4   7   0   2   8   2   5   8 154  25   4  21   3   4   0  14   2   5\n",
      "    1   1   0]\n",
      " [  9   2   3   2  12   0   8  19  42  79   3  38   4   5   0  14   0   2\n",
      "    1   2   1]\n",
      " [  0   4   1   2   2   0   0   1  22   2  11   0   1   0   0   1   0   1\n",
      "    0   0   1]\n",
      " [  2   2   6   0   6   5   6  13  19  37   1 141  16   1   2   4   1   2\n",
      "    2   3   1]\n",
      " [  3   5   2   1   3   2   1   7   6   8   1  13  21   4   0   3   4   4\n",
      "    0   1   0]\n",
      " [  3   3   2   2   8   0   0   1   2   1   0   3   2 250  10   1   1   2\n",
      "    1   4   1]\n",
      " [  4   1   2   0   2   0   1   2   0   0   0   0   1  41  13   1   0   1\n",
      "    0   0   1]\n",
      " [  4   2   1   0  12   2   3  14   6  11   0   6   1   2   0  82   1   0\n",
      "    1   0   0]\n",
      " [ 16   4   6   1   3   2   0   1   3   2   0   2   1   4   2   1  48   6\n",
      "    4   1   2]\n",
      " [  4   5   3   1   5   3   0   2   1   1   1   3   2  14   4   1   8  28\n",
      "    2   2   2]\n",
      " [  5   4   0   1   0   0   0   0   1   2   0   4   0   1   0   0   5   3\n",
      "   25   5   2]\n",
      " [  3   4   0   0   1   0   0   4   3   4   0   4   1   7   0   2   2   3\n",
      "    6  30   4]\n",
      " [  6   2   0   2   0   0   0   0   1   3   0   1   0   2   0   1   9   3\n",
      "    3  10  19]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(max_iter=50)\n",
      "train time: 0.110s\n",
      "test time:  0.001s\n",
      "accuracy:   0.371\n",
      "dimensionality: 4229\n",
      "density: 0.267732\n",
      "top 10 keywords per class:\n",
      "11-1021.00: epm biological sses iah ann cla geo assitant models wastewater\n",
      "11-2021.00: elp hhonors ledger library ba infra chcn servicing mrf gifts\n",
      "11-2022.00: manufactuirng craft cre cx connectrix cl servies brands protectiv...\n",
      "11-3031.02: neede merchandise operations governanc freight weekends prem pd w...\n",
      "13-1111.00: forecasting leadership abap hfm accenture fss gto archeology face...\n",
      "13-2051.00: technlgst rosslyn intelligent cta fmx engneer dss cont cisa faitas\n",
      "15-1121.00: armament epic sub scrub ilss zoning institution overall ww biztalk\n",
      "15-1122.00: review malware poa dts isse ite intell mcafee intrusion librarian\n",
      "15-1132.00: cps creek ibm sensing publisher dwbi orthopaedics suicide frequen...\n",
      "15-1133.00: frontend cxp payload enviromental sl machine usff fcs measure spe...\n",
      "15-1134.00: aid rational mvc osisoft proddev lob qc bps drupal sharepoint\n",
      "15-1142.00: appdynamics estimating weapon mobileiron gcss ogc controllers cha...\n",
      "15-1151.00: passive defined week kiosk dacm rf pool scanner spear servcie\n",
      "29-1141.00: coverage inpt physical block cvor ssdp carriage rcm stonesprings tlv\n",
      "31-1014.00: thoracic residence bh sleep sn patient pbuse trades tbi oncolog\n",
      "33-3021.06: corps orsa biotechnology developler cio possess espionage xb cart...\n",
      "41-2031.00: peppers nex supv furniture club step underwriter salesfloor cosme...\n",
      "43-4051.00: rws circuit electroencephalogram eeg marriott cva giver mtf teler...\n",
      "49-3023.02: port visual receivable ahq intermodal signals supervisory lube al...\n",
      "49-9071.00: svc rec henico landfill mould featherbed readvertisement grade pe...\n",
      "53-3032.00: farm class archives discrep armory proposed overseas govcloud mea...\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.25      0.18      0.21       147\n",
      "  11-2021.00       0.36      0.37      0.37       195\n",
      "  11-2022.00       0.27      0.18      0.22       119\n",
      "  11-3031.02       0.36      0.41      0.38       108\n",
      "  13-1111.00       0.29      0.29      0.29       173\n",
      "  13-2051.00       0.22      0.31      0.26        72\n",
      "  15-1121.00       0.19      0.24      0.21       110\n",
      "  15-1122.00       0.41      0.52      0.46       263\n",
      "  15-1132.00       0.46      0.40      0.43       270\n",
      "  15-1133.00       0.28      0.20      0.24       246\n",
      "  15-1134.00       0.38      0.31      0.34        49\n",
      "  15-1142.00       0.45      0.49      0.47       270\n",
      "  15-1151.00       0.17      0.13      0.15        89\n",
      "  29-1141.00       0.71      0.70      0.71       297\n",
      "  31-1014.00       0.25      0.27      0.26        70\n",
      "  33-3021.06       0.40      0.37      0.38       148\n",
      "  41-2031.00       0.32      0.39      0.35       109\n",
      "  43-4051.00       0.23      0.27      0.25        92\n",
      "  49-3023.02       0.31      0.33      0.32        58\n",
      "  49-9071.00       0.23      0.28      0.25        78\n",
      "  53-3032.00       0.29      0.23      0.25        62\n",
      "\n",
      "    accuracy                           0.37      3025\n",
      "   macro avg       0.33      0.33      0.32      3025\n",
      "weighted avg       0.37      0.37      0.37      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 26   9   3  13  12   7   6   5   3   4   2   4   2   7   2   5  18   9\n",
      "    2   4   4]\n",
      " [ 16  73  14   8  15   8   4  14   9   5   1   3   2   2   2   3   4   9\n",
      "    1   1   1]\n",
      " [  6  32  22  11   3   4   3   4   2   2   1   3   1   2   0   3  11   4\n",
      "    2   2   1]\n",
      " [  4   7   4  44  11  11   1   4   2   0   0   0   1   1   0   2   7   4\n",
      "    3   1   1]\n",
      " [  7  10   6   5  51   7  14  21   7   4   0   9   5   3   2   5   3  10\n",
      "    1   1   2]\n",
      " [  5   0   0   5   7  22   5   6   4   4   0   2   0   4   1   3   1   0\n",
      "    1   1   1]\n",
      " [  1   4   1   2  17   3  26   9  10  11   1   5   2   1   0  12   1   1\n",
      "    1   2   0]\n",
      " [  1  19   1   5   9   2   9 137   9  11   0  25   7   2   1   9   3   5\n",
      "    3   4   1]\n",
      " [  6   9   2   4   9  10  14  27 109  24   6  21   3   2   1  13   2   4\n",
      "    0   2   2]\n",
      " [  2   8   3   6   8   3  11  31  36  50   7  46   6   2   1  14   4   1\n",
      "    1   4   2]\n",
      " [  0   2   1   0   1   0   3   7  14   1  15   1   0   0   0   1   0   1\n",
      "    0   0   2]\n",
      " [  1   1   3   3   3   6  13  23  16  31   3 131  14   2   2   3   5   2\n",
      "    1   6   1]\n",
      " [  4   4   2   0   4   2   3   9   3   9   2  14  12   2   1   5   4   3\n",
      "    1   5   0]\n",
      " [  5   2   1   1   5   1   5   0   1   3   0   4   2 208  30   2   1  13\n",
      "    4   8   1]\n",
      " [  1   1   2   1   0   0   2   2   1   2   0   1   0  32  19   0   1   3\n",
      "    0   0   2]\n",
      " [  2   0   0   3  15   6   9  27   7   4   1  11   1   2   1  55   0   1\n",
      "    1   1   1]\n",
      " [  9   6   9   3   3   1   2   0   1   1   0   2   2   4   2   1  43   4\n",
      "    8   4   4]\n",
      " [  3   5   3   2   2   1   2   5   2   1   1   1   4  11   3   2   4  25\n",
      "    7   5   3]\n",
      " [  2   0   0   2   0   1   0   1   1   2   0   3   3   2   0   0   9   2\n",
      "   19   9   2]\n",
      " [  1   8   4   2   0   3   3   4   1   4   0   3   2   3   6   0   3   3\n",
      "    2  22   4]\n",
      " [  3   1   0   1   1   0   1   0   0   3   0   1   1   1   3   1  11   3\n",
      "    4  13  14]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(max_iter=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.249s\n",
      "test time:  0.001s\n",
      "accuracy:   0.400\n",
      "dimensionality: 4229\n",
      "density: 0.615016\n",
      "top 10 keywords per class:\n",
      "11-1021.00: geo govcon bowdoin cla assitant ann models copper wastewater opera\n",
      "11-2021.00: accessories solidfire infra paas speaking mrf lewin hhonors servi...\n",
      "11-2022.00: institutions enforcement resilience insight protective marketplac...\n",
      "11-3031.02: merchandise pd swim rotational governanc weekends freight prem if...\n",
      "13-1111.00: fss available excellence forecasting cqi institutional interfaces...\n",
      "13-2051.00: dss frc cta verification technlgst ccmr rosslyn fmx cisa faitas\n",
      "15-1121.00: hcp lifecycle prncpl improvised doc ilss overall maritime biztalk ww\n",
      "15-1122.00: dlp families ite isse reviewer poa intell librarian intrusion and...\n",
      "15-1132.00: dart freelancer bilinqual hot cop publisher ibm dwbi lims suicide\n",
      "15-1133.00: machine architectures measure fcs ecosystem cxp frontend battle m...\n",
      "15-1134.00: mvc pdx ssbu bike opportunity qc drupal restful backbonejs lob\n",
      "15-1142.00: angen cpi sysems seim mobileiron controllers ogc appdynamics weap...\n",
      "15-1151.00: vip navigation spear scanner code pos recon tom cmv kiosk\n",
      "29-1141.00: fourth secours profesional inpt pretrial dw lieutenant tlv ssdp c...\n",
      "31-1014.00: pbuse trades cardiothoracic tbi sleep nerancy bh specialists sn o...\n",
      "33-3021.06: corps critical developers patent classified possess idiq biotechn...\n",
      "41-2031.00: prestige underwriter selling mitigation distributor step nex sale...\n",
      "43-4051.00: sched french mtf telerecruiter pcmm multicultural giver hometeam ...\n",
      "49-3023.02: pack groundskeeper assembly medium lube signals intermodal visual...\n",
      "49-9071.00: personalized readvertisement genl itops mould pet rec nf landfill...\n",
      "53-3032.00: suite way eu driver proposed meadowcreek weigh govcloud route arc...\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.19      0.22      0.21       147\n",
      "  11-2021.00       0.44      0.37      0.40       195\n",
      "  11-2022.00       0.31      0.34      0.33       119\n",
      "  11-3031.02       0.40      0.40      0.40       108\n",
      "  13-1111.00       0.28      0.30      0.29       173\n",
      "  13-2051.00       0.26      0.26      0.26        72\n",
      "  15-1121.00       0.23      0.24      0.24       110\n",
      "  15-1122.00       0.52      0.51      0.52       263\n",
      "  15-1132.00       0.44      0.39      0.41       270\n",
      "  15-1133.00       0.30      0.40      0.35       246\n",
      "  15-1134.00       0.35      0.31      0.33        49\n",
      "  15-1142.00       0.53      0.40      0.45       270\n",
      "  15-1151.00       0.28      0.21      0.24        89\n",
      "  29-1141.00       0.66      0.73      0.69       297\n",
      "  31-1014.00       0.21      0.20      0.20        70\n",
      "  33-3021.06       0.44      0.51      0.48       148\n",
      "  41-2031.00       0.44      0.38      0.41       109\n",
      "  43-4051.00       0.32      0.29      0.31        92\n",
      "  49-3023.02       0.37      0.43      0.40        58\n",
      "  49-9071.00       0.32      0.32      0.32        78\n",
      "  53-3032.00       0.34      0.29      0.31        62\n",
      "\n",
      "    accuracy                           0.40      3025\n",
      "   macro avg       0.36      0.36      0.36      3025\n",
      "weighted avg       0.40      0.40      0.40      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 33   9   9   8  14   8   4   3   2  13   2   1   3  11   4   4   9   3\n",
      "    1   4   2]\n",
      " [ 18  72  17   3  18   5   6   2  10  10   2   4   3   5   4   7   3   3\n",
      "    0   1   2]\n",
      " [  7  18  41  12   6   5   1   3   5   2   0   0   1   3   1   2   4   5\n",
      "    2   1   0]\n",
      " [  8   8   8  43  13   9   2   3   0   0   0   1   0   2   1   1   4   3\n",
      "    1   1   0]\n",
      " [ 15  14   8  10  52   2   6   8   8  12   1   7   4   5   1   6   2   6\n",
      "    2   1   3]\n",
      " [  6   1   1   7  10  19   4   6   2   7   0   1   0   2   1   3   0   0\n",
      "    1   0   1]\n",
      " [  3   2   2   1  14   3  26   7   9  18   2   3   0   4   2  12   0   0\n",
      "    0   2   0]\n",
      " [  7   8   3   4   8   3   6 135  11  29   0  21   2   2   1  14   1   2\n",
      "    3   3   0]\n",
      " [  3   6   2   2  11   3  11  13 104  54  13  14   6   4   2  12   1   3\n",
      "    2   3   1]\n",
      " [  6   2   4   4   9   2  10  21  30  99   5  20   3   3   3  14   1   1\n",
      "    2   6   1]\n",
      " [  0   4   1   1   1   0   1   4  13   3  15   1   1   0   0   1   0   1\n",
      "    0   1   1]\n",
      " [  2   1   5   4   3   6   7  20  23  47   1 108  15   4   1  10   1   2\n",
      "    3   7   0]\n",
      " [  8   4   2   0   1   2   4   9   4  10   1   9  19   2   0   4   3   3\n",
      "    2   1   1]\n",
      " [  7   1   3   2   3   2   8   0   3   2   0   2   0 217  22   2   0  12\n",
      "    2   7   2]\n",
      " [  2   1   2   0   0   0   3   3   0   0   0   0   0  39  14   0   0   3\n",
      "    0   1   2]\n",
      " [  5   0   3   1  16   0   6  14   2  12   0   5   3   3   0  76   0   2\n",
      "    0   0   0]\n",
      " [ 18   5  10   1   2   0   2   0   3   1   0   1   2   2   2   1  41   3\n",
      "    7   1   7]\n",
      " [  9   3   5   4   2   3   1   2   0   0   1   1   2  12   6   1   5  27\n",
      "    3   2   3]\n",
      " [  4   1   0   1   0   1   0   0   0   3   0   2   2   1   1   0   6   2\n",
      "   25   4   5]\n",
      " [  4   5   3   0   1   0   2   3   6   3   0   2   1   5   2   1   2   3\n",
      "    6  25   4]\n",
      " [  6   0   3   0   0   0   1   2   0   2   0   2   0   3   0   1  10   1\n",
      "    5   8  18]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "train time: 0.009s\n",
      "test time:  0.790s\n",
      "accuracy:   0.444\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.22      0.31      0.26       147\n",
      "  11-2021.00       0.39      0.46      0.42       195\n",
      "  11-2022.00       0.36      0.26      0.30       119\n",
      "  11-3031.02       0.45      0.44      0.44       108\n",
      "  13-1111.00       0.27      0.35      0.31       173\n",
      "  13-2051.00       0.37      0.32      0.34        72\n",
      "  15-1121.00       0.27      0.19      0.22       110\n",
      "  15-1122.00       0.49      0.56      0.52       263\n",
      "  15-1132.00       0.48      0.61      0.54       270\n",
      "  15-1133.00       0.33      0.33      0.33       246\n",
      "  15-1134.00       0.44      0.14      0.22        49\n",
      "  15-1142.00       0.49      0.53      0.51       270\n",
      "  15-1151.00       0.30      0.17      0.22        89\n",
      "  29-1141.00       0.72      0.83      0.77       297\n",
      "  31-1014.00       0.48      0.20      0.28        70\n",
      "  33-3021.06       0.53      0.45      0.49       148\n",
      "  41-2031.00       0.51      0.47      0.49       109\n",
      "  43-4051.00       0.38      0.28      0.33        92\n",
      "  49-3023.02       0.40      0.40      0.40        58\n",
      "  49-9071.00       0.51      0.31      0.38        78\n",
      "  53-3032.00       0.68      0.24      0.36        62\n",
      "\n",
      "    accuracy                           0.44      3025\n",
      "   macro avg       0.43      0.37      0.39      3025\n",
      "weighted avg       0.45      0.44      0.44      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 46  13   5   5  17   4   1  10   3  12   1   5   1   9   1   1   5   6\n",
      "    1   1   0]\n",
      " [ 20  90  12   5  16   2   2   7  17   9   1   2   0   2   0   5   4   1\n",
      "    0   0   0]\n",
      " [ 15  34  31   6   4   1   0   5   3   3   0   3   1   1   0   1   6   3\n",
      "    1   1   0]\n",
      " [  9   9   5  47  12   6   2   4   1   0   0   3   0   0   0   3   3   4\n",
      "    0   0   0]\n",
      " [ 19  15   3   5  61   3   7  16   5   8   0   8   5   2   0   6   1   6\n",
      "    1   0   2]\n",
      " [  5   4   0   8   6  23   5   7   4   2   0   1   1   3   0   3   0   0\n",
      "    0   0   0]\n",
      " [  7   3   4   1  12   3  21   9  13  13   1   8   0   2   0  12   0   0\n",
      "    0   1   0]\n",
      " [  8   6   2   6  12   0   4 147  17  20   0  21   4   3   0   8   0   1\n",
      "    3   1   0]\n",
      " [  5   8   0   3  15   3   4  12 165  21   1  17   3   3   1   2   2   3\n",
      "    2   0   0]\n",
      " [ 12   5   3   2  23   1  14  13  40  81   2  36   3   4   0   4   0   1\n",
      "    1   0   1]\n",
      " [  0   3   0   1   3   0   2   1  28   2   7   2   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  2   4   3   1   8   5   5  20  18  37   0 143  10   2   1   2   1   1\n",
      "    4   3   0]\n",
      " [  6   4   1   2   5   3   3  11   8   6   2  12  15   0   0   5   1   2\n",
      "    2   1   0]\n",
      " [  4   4   3   2   4   0   1   5   1   2   0   3   2 247   8   0   3   4\n",
      "    2   2   0]\n",
      " [  4   1   3   0   2   0   1   4   0   1   0   1   0  37  14   1   0   1\n",
      "    0   0   0]\n",
      " [  3   4   0   1  13   2   3  20  11  14   1   6   2   1   0  66   1   0\n",
      "    0   0   0]\n",
      " [ 16   9   6   2   2   2   0   0   2   3   0   1   1   2   0   1  51   3\n",
      "    4   2   2]\n",
      " [  8   4   3   2   5   3   0   2   1   2   0   4   1  13   3   3   7  26\n",
      "    3   2   0]\n",
      " [  5   3   1   2   1   1   2   0   1   2   0   3   1   2   0   0   6   2\n",
      "   23   3   0]\n",
      " [  7   4   1   0   0   0   2   8   5   5   0   7   0   4   0   1   1   1\n",
      "    6  24   2]\n",
      " [  5   3   0   3   1   0   0   0   0   4   0   4   0   4   1   0   8   3\n",
      "    5   6  15]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 9.834s\n",
      "test time:  0.149s\n",
      "accuracy:   0.454\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.26      0.33      0.30       147\n",
      "  11-2021.00       0.41      0.47      0.44       195\n",
      "  11-2022.00       0.39      0.34      0.37       119\n",
      "  11-3031.02       0.58      0.46      0.52       108\n",
      "  13-1111.00       0.36      0.37      0.36       173\n",
      "  13-2051.00       0.35      0.26      0.30        72\n",
      "  15-1121.00       0.34      0.20      0.25       110\n",
      "  15-1122.00       0.58      0.57      0.58       263\n",
      "  15-1132.00       0.47      0.55      0.51       270\n",
      "  15-1133.00       0.33      0.33      0.33       246\n",
      "  15-1134.00       0.28      0.14      0.19        49\n",
      "  15-1142.00       0.53      0.57      0.55       270\n",
      "  15-1151.00       0.23      0.18      0.20        89\n",
      "  29-1141.00       0.67      0.82      0.74       297\n",
      "  31-1014.00       0.43      0.14      0.22        70\n",
      "  33-3021.06       0.42      0.53      0.47       148\n",
      "  41-2031.00       0.50      0.51      0.51       109\n",
      "  43-4051.00       0.33      0.32      0.32        92\n",
      "  49-3023.02       0.39      0.43      0.41        58\n",
      "  49-9071.00       0.39      0.31      0.35        78\n",
      "  53-3032.00       0.42      0.27      0.33        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.41      0.39      0.39      3025\n",
      "weighted avg       0.45      0.45      0.44      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 49  17   4   3  10   3   2   0   4  10   2   3   0  11   1   5  13   4\n",
      "    1   5   0]\n",
      " [ 18  91  18   4  14   4   1   7   7   5   1   3   2   5   0   8   4   1\n",
      "    0   1   1]\n",
      " [ 12  28  41   5   4   3   0   3   5   1   0   3   0   4   0   0   6   3\n",
      "    0   1   0]\n",
      " [  9   7  11  50   5   4   2   4   1   1   0   1   0   1   0   3   3   4\n",
      "    0   2   0]\n",
      " [  7  11   4   1  64   3   7  10  16   7   0   7   7   5   0  11   1   6\n",
      "    1   2   3]\n",
      " [  7   3   0  11   3  19   4   8   3   4   0   1   1   2   0   4   1   1\n",
      "    0   0   0]\n",
      " [  5   4   0   1  12   2  22   9   9  13   4   4   2   4   0  16   0   1\n",
      "    0   0   2]\n",
      " [  3   4   2   5  10   1   4 151  11  21   1  16   4   2   2  17   0   1\n",
      "    3   3   2]\n",
      " [  2  10   2   1  11   2   4   6 149  31   6  21   2   8   0   9   1   3\n",
      "    2   0   0]\n",
      " [  5   5   3   1  10   1   7  15  46  80   2  38   8   2   0  15   0   2\n",
      "    1   3   2]\n",
      " [  1   2   0   0   3   2   0   1  23   5   7   1   0   0   0   2   0   1\n",
      "    0   0   1]\n",
      " [  3   0   2   0   8   1   3  15  20  36   0 153  11   4   0   7   1   1\n",
      "    3   2   0]\n",
      " [  6   7   1   0   4   4   2   7   5   7   1  16  16   4   0   3   2   1\n",
      "    2   0   1]\n",
      " [  8   5   2   0   3   0   1   2   1   2   0   1   2 243   6   1   1  10\n",
      "    3   5   1]\n",
      " [  6   0   1   0   1   0   1   2   1   2   0   1   0  40  10   1   1   1\n",
      "    1   1   0]\n",
      " [  9   4   0   2  10   1   3  15   7   6   0   6   3   3   0  78   0   1\n",
      "    0   0   0]\n",
      " [ 14   9   4   1   3   1   0   1   2   0   0   1   2   2   0   0  56   5\n",
      "    5   1   2]\n",
      " [  8   6   5   0   1   3   0   1   0   2   0   2   2  11   4   0   9  29\n",
      "    2   3   4]\n",
      " [  4   3   3   0   1   0   0   1   1   2   1   4   2   2   0   0   3   2\n",
      "   25   2   2]\n",
      " [  5   3   2   0   0   1   1   0   3   4   0   4   5   7   0   4   1   1\n",
      "   11  24   2]\n",
      " [  4   1   0   1   1   0   0   2   0   3   0   2   0   3   0   1   8   9\n",
      "    4   6  17]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, tol=0.001)\n",
      "train time: 0.353s\n",
      "test time:  0.001s\n",
      "accuracy:   0.453\n",
      "dimensionality: 4229\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "11-1021.00: memoria fresh official interactive models qpm refurb sses wastewa...\n",
      "11-2021.00: product servicing personalization solidfire campaign sustainable ...\n",
      "11-2022.00: insight softlines protective connectrix american underpayments ac...\n",
      "11-3031.02: recognition crossings audit outcomes outsourcing forecast vendor ...\n",
      "13-1111.00: dio facets institutional continuty sevices accenture mai adoption...\n",
      "13-2051.00: budget mem cta instuctor cisa storeroom fmx cpic alm fpa\n",
      "15-1121.00: oversight zoning biztalk ppbe lifecycle maritime mss appsw lingui...\n",
      "15-1122.00: adp tscm isse mcafee authorization fingerprinting intrusion soc l...\n",
      "15-1132.00: migration infopath cps config atlassian netsuite hot cucm tbma trust\n",
      "15-1133.00: missions gmi payload fielded dasd nro gpu optical webmaster spectrum\n",
      "15-1134.00: jbpm brava sofware osisoft rational mvc restful lob sharepoint dr...\n",
      "15-1142.00: mobileiron chapter appdynamics rqd iafnos lan ins administrator e...\n",
      "15-1151.00: ssae scanner spear saa vip ssds passive deskside game tom\n",
      "29-1141.00: pharmacy tlv dw infection eap living hh case rcm rn\n",
      "31-1014.00: dietitian residence nerancy bh pbuse academic tbi sn monitor sleep\n",
      "33-3021.06: osint watchlist orsa source elint intelligence biotechnology wmd ...\n",
      "41-2031.00: signage salesfloor peppers garage supv underwriter cosmetics nex ...\n",
      "43-4051.00: hde telerecruiter clerical sched sbs delinquency rws mtf promotio...\n",
      "49-3023.02: custodial carpentry olympus reprensentative mini body assembly po...\n",
      "49-9071.00: dmv laborer itops renovations pet datapower roadway maintenance a...\n",
      "53-3032.00: eu armed discrep govcloud loom lst drivers archery route driver\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.24      0.27      0.25       147\n",
      "  11-2021.00       0.42      0.42      0.42       195\n",
      "  11-2022.00       0.37      0.34      0.35       119\n",
      "  11-3031.02       0.47      0.45      0.46       108\n",
      "  13-1111.00       0.33      0.36      0.34       173\n",
      "  13-2051.00       0.40      0.38      0.39        72\n",
      "  15-1121.00       0.32      0.20      0.25       110\n",
      "  15-1122.00       0.60      0.57      0.58       263\n",
      "  15-1132.00       0.48      0.55      0.51       270\n",
      "  15-1133.00       0.32      0.31      0.31       246\n",
      "  15-1134.00       0.42      0.27      0.33        49\n",
      "  15-1142.00       0.52      0.54      0.53       270\n",
      "  15-1151.00       0.27      0.22      0.25        89\n",
      "  29-1141.00       0.70      0.82      0.76       297\n",
      "  31-1014.00       0.32      0.21      0.26        70\n",
      "  33-3021.06       0.49      0.58      0.53       148\n",
      "  41-2031.00       0.44      0.46      0.45       109\n",
      "  43-4051.00       0.35      0.36      0.36        92\n",
      "  49-3023.02       0.35      0.38      0.37        58\n",
      "  49-9071.00       0.38      0.35      0.36        78\n",
      "  53-3032.00       0.43      0.31      0.36        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.41      0.40      0.40      3025\n",
      "weighted avg       0.45      0.45      0.45      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 39  13   5   7  12   5   3   4   5  12   0   1   1   9   1   6  12   4\n",
      "    2   4   2]\n",
      " [ 14  82  20   5  17   6   3   5  12   6   1   2   2   2   3   4   4   4\n",
      "    0   3   0]\n",
      " [  7  26  40   8   3   3   1   3   4   2   1   2   1   3   0   2   6   4\n",
      "    2   1   0]\n",
      " [  7   6   9  49  12   8   0   0   3   0   0   2   2   0   0   0   5   3\n",
      "    1   1   0]\n",
      " [ 17  10   5   8  62   4   7   7   8   8   1   8   4   4   1   6   1   8\n",
      "    2   0   2]\n",
      " [  3   1   0   6   8  27   1   7   2   5   0   1   1   2   1   4   1   0\n",
      "    1   0   1]\n",
      " [  3   3   1   0  16   4  22   6  10  16   2   5   1   4   2  12   0   0\n",
      "    2   1   0]\n",
      " [  5   7   1   6  10   0   4 149  12  19   0  21   4   1   0  11   2   3\n",
      "    4   4   0]\n",
      " [  4   7   0   3   9   2   6   9 148  27   7  20   4   4   0  11   1   5\n",
      "    1   1   1]\n",
      " [  9   3   3   2  10   1   8  17  42  76   3  40   4   3   1  17   1   1\n",
      "    2   2   1]\n",
      " [  0   4   1   0   2   0   0   1  21   2  13   0   1   0   0   1   0   1\n",
      "    0   0   2]\n",
      " [  1   3   4   0   4   5   6  13  19  36   1 146  16   1   1   5   1   2\n",
      "    2   3   1]\n",
      " [  4   5   2   2   4   2   1   7   7   7   1  11  20   2   0   4   4   2\n",
      "    2   1   1]\n",
      " [  4   3   2   2   4   0   2   0   2   2   0   3   3 245  14   1   1   4\n",
      "    1   3   1]\n",
      " [  3   1   1   0   2   0   1   2   0   0   0   0   1  41  15   0   0   2\n",
      "    0   0   1]\n",
      " [  4   2   1   0   9   0   3  14   7  10   0   7   1   3   0  86   0   0\n",
      "    0   1   0]\n",
      " [ 16   5   7   1   2   0   0   0   2   2   0   1   2   3   1   1  50   7\n",
      "    5   2   2]\n",
      " [  5   3   2   2   3   1   0   2   1   1   1   3   2  12   5   2   6  33\n",
      "    2   2   4]\n",
      " [  4   3   1   1   0   0   0   0   1   2   0   4   1   1   1   0   6   4\n",
      "   22   5   2]\n",
      " [  4   4   2   0   0   0   0   3   3   3   0   4   2   7   1   1   2   4\n",
      "    7  27   4]\n",
      " [  7   2   0   2   0   0   0   0   0   2   0   0   0   3   0   1  10   2\n",
      "    4  10  19]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.156s\n",
      "test time:  0.001s\n",
      "accuracy:   0.456\n",
      "dimensionality: 4229\n",
      "density: 0.308944\n",
      "top 10 keywords per class:\n",
      "11-1021.00: louis initiative attorney outbound shopping qpm goods party store...\n",
      "11-2021.00: campaign iot hhonors alliances art product channel capture brand ...\n",
      "11-2022.00: immediately intl major pharmaceutical craft account smb od prime ...\n",
      "11-3031.02: controller hrs accounting sec fc recognition audit accountant hou...\n",
      "13-1111.00: change acquistion facets acc mlt effectiveness ocm adoption accen...\n",
      "13-2051.00: economic investments isrm cont alm fp budget fpa treasury cpic\n",
      "15-1121.00: enabled gl order maritime fighter strike mss appsw linguist epic\n",
      "15-1122.00: isso cnd fingerprinting ids malware soc splunk authorization assu...\n",
      "15-1132.00: config trust netsuite developer hot salesforce android ui devops ...\n",
      "15-1133.00: missions satellite payload ground spacecraft spectrum optical com...\n",
      "15-1134.00: script aem jbpm sofware brava rational osisoft mvc drupal sharepoint\n",
      "15-1142.00: storage voip engr wan lan iafnos sds vmware administrator network\n",
      "15-1151.00: desktop game recording arboretum passive printer css vip ssds des...\n",
      "29-1141.00: appeals hospital rehabilitation lpn therapist rcm case clinical n...\n",
      "31-1014.00: asst pca cv aide sleep academic cna nursing certified monitor\n",
      "33-3021.06: watchlist collection elint target citp wmd targeting imagery inte...\n",
      "41-2031.00: decor toyota sprint shoes footwear prestige apparel cosmetics ret...\n",
      "43-4051.00: direct mtf promotions rws olde delinquency caregiver clerical lea...\n",
      "49-3023.02: ase exhaust shop diesel heavy automotive mechanic tire body lube\n",
      "49-9071.00: apartment welder apartments roadway datapower ammonia espan ol ma...\n",
      "53-3032.00: motor weekly archery armed lst truck loom route drivers driver\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.29      0.22      0.25       147\n",
      "  11-2021.00       0.44      0.48      0.46       195\n",
      "  11-2022.00       0.39      0.33      0.35       119\n",
      "  11-3031.02       0.51      0.43      0.46       108\n",
      "  13-1111.00       0.35      0.34      0.34       173\n",
      "  13-2051.00       0.39      0.38      0.38        72\n",
      "  15-1121.00       0.32      0.21      0.25       110\n",
      "  15-1122.00       0.57      0.57      0.57       263\n",
      "  15-1132.00       0.48      0.57      0.52       270\n",
      "  15-1133.00       0.33      0.24      0.28       246\n",
      "  15-1134.00       0.42      0.22      0.29        49\n",
      "  15-1142.00       0.49      0.59      0.54       270\n",
      "  15-1151.00       0.32      0.15      0.20        89\n",
      "  29-1141.00       0.66      0.86      0.75       297\n",
      "  31-1014.00       0.31      0.23      0.26        70\n",
      "  33-3021.06       0.44      0.60      0.51       148\n",
      "  41-2031.00       0.42      0.51      0.46       109\n",
      "  43-4051.00       0.34      0.27      0.30        92\n",
      "  49-3023.02       0.36      0.41      0.38        58\n",
      "  49-9071.00       0.38      0.37      0.38        78\n",
      "  53-3032.00       0.37      0.31      0.34        62\n",
      "\n",
      "    accuracy                           0.46      3025\n",
      "   macro avg       0.41      0.39      0.39      3025\n",
      "weighted avg       0.44      0.46      0.44      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 32  14   2   6  14   5   4   4   3  11   0   3   3  16   4   7  11   1\n",
      "    2   3   2]\n",
      " [  9  93  20   3  11   3   4   5  12   3   0   2   1   4   5   5   7   4\n",
      "    2   2   0]\n",
      " [  3  25  39   7   6   5   1   3   6   2   0   2   1   3   0   4   6   2\n",
      "    2   2   0]\n",
      " [  6   6   7  46   6   9   1   3   2   0   1   3   0   1   0   2   7   5\n",
      "    1   1   1]\n",
      " [  9  12   7   4  59   6   9   8  11   5   0  11   2   6   0   9   3   7\n",
      "    1   1   3]\n",
      " [  2   2   0   5   9  27   2   7   3   3   0   1   0   3   1   5   0   1\n",
      "    0   0   1]\n",
      " [  2   5   2   0  12   3  23   8  11   7   2   5   0   3   3  18   0   3\n",
      "    0   1   2]\n",
      " [  2   6   2   4   5   0   4 150  10  18   0  25   3   2   2  16   2   4\n",
      "    4   3   1]\n",
      " [  2   8   0   1  11   2   1  11 155  24   4  18   2   5   1  16   2   4\n",
      "    1   1   1]\n",
      " [  9   5   3   2  10   1   6  18  45  59   5  51   3   5   1  16   1   0\n",
      "    2   3   1]\n",
      " [  0   4   2   1   2   0   0   1  24   1  11   0   1   0   0   0   0   1\n",
      "    0   0   1]\n",
      " [  1   2   3   1   4   3   9  13  21  23   2 160  10   1   1   3   2   2\n",
      "    4   3   2]\n",
      " [  1   4   1   2   4   2   1   7   7   6   1  16  13   5   1   6   4   2\n",
      "    3   1   2]\n",
      " [  3   2   1   2   3   1   0   2   2   0   0   4   0 255   9   1   1   3\n",
      "    2   5   1]\n",
      " [  2   0   2   0   1   0   1   3   0   0   0   0   0  42  16   0   0   2\n",
      "    0   0   1]\n",
      " [  3   4   1   0   7   1   5  13   6   7   0   8   1   3   0  89   0   0\n",
      "    0   0   0]\n",
      " [ 13   4   6   0   3   1   0   1   2   2   0   1   0   5   1   1  56   3\n",
      "    5   3   2]\n",
      " [  1   4   2   4   2   1   0   2   1   1   0   2   1  15   5   2  12  25\n",
      "    4   3   5]\n",
      " [  1   4   0   2   0   0   0   1   2   2   0   3   0   1   1   0   6   1\n",
      "   24   7   3]\n",
      " [  2   5   1   0   2   0   0   2   2   4   0   7   0   7   0   2   2   3\n",
      "    7  29   3]\n",
      " [  7   1   0   1   0   0   2   0   0   2   0   3   0   2   0   1  12   1\n",
      "    3   8  19]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
      "train time: 0.799s\n",
      "test time:  0.001s\n",
      "accuracy:   0.454\n",
      "dimensionality: 4229\n",
      "density: 0.120889\n",
      "top 10 keywords per class:\n",
      "11-1021.00: qpm rel wastewater looking copper vcu accred analys fiscal initia...\n",
      "11-2021.00: campaign williamsburgh chcn servicing hokievision gifts marketing...\n",
      "11-2022.00: crunch acct gcse gnc states craft signing janssen american immedi...\n",
      "11-3031.02: coodinator db watercraft vendor swim buying lcsp forecast hours tax\n",
      "13-1111.00: fss ocb institutional adoption grow interfaces mai procure accent...\n",
      "13-2051.00: radiometric fpa frc nof alm cisa faitas cdia cont isrm\n",
      "15-1121.00: scrub forestry virology biztalk prncpl mss appsw maritime linguis...\n",
      "15-1122.00: mcafee authorization soc security librarian locator isse fingerpr...\n",
      "15-1132.00: lims dart cucm excitation freelancer infopath tbma hot suicide trust\n",
      "15-1133.00: ssdi cxp amberdale nro spectrum sl gpu webmaster jtaad logic\n",
      "15-1134.00: sofware pdx serice backbonejs restful webpage workers sharepoint ...\n",
      "15-1142.00: acss datacenter controllers engr chapter sysems sds fnc weapon ap...\n",
      "15-1151.00: ssae rtta cmv mechanism kiosk ccm servers defined treaties cabinet\n",
      "29-1141.00: coverage fourth hh msw rcm stoneridge disease eap rn ssdp\n",
      "31-1014.00: animal nerancy bh monitor shelter travelers sn cv academic sleep\n",
      "33-3021.06: orsa urdu possess biotechnology atc wmd osint emass imagery citp\n",
      "41-2031.00: udb dynamic fitting accelerated mitigation cosmetics csa nex pres...\n",
      "43-4051.00: sched delinquency caregiver telerecruiter sbs rws guard mtf promo...\n",
      "49-3023.02: exhaust pack tire body positon predatory framing lube npms ground...\n",
      "49-9071.00: studio roasting cao closing genl datapower roadway ammonia ol nf\n",
      "53-3032.00: govcloud meadowcreek armed loom class lst route archery drivers d...\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.27      0.29      0.28       147\n",
      "  11-2021.00       0.45      0.45      0.45       195\n",
      "  11-2022.00       0.39      0.34      0.36       119\n",
      "  11-3031.02       0.46      0.46      0.46       108\n",
      "  13-1111.00       0.33      0.38      0.35       173\n",
      "  13-2051.00       0.37      0.36      0.37        72\n",
      "  15-1121.00       0.33      0.19      0.24       110\n",
      "  15-1122.00       0.59      0.56      0.58       263\n",
      "  15-1132.00       0.48      0.56      0.52       270\n",
      "  15-1133.00       0.34      0.34      0.34       246\n",
      "  15-1134.00       0.41      0.22      0.29        49\n",
      "  15-1142.00       0.51      0.53      0.52       270\n",
      "  15-1151.00       0.28      0.21      0.24        89\n",
      "  29-1141.00       0.69      0.83      0.75       297\n",
      "  31-1014.00       0.33      0.21      0.26        70\n",
      "  33-3021.06       0.45      0.55      0.49       148\n",
      "  41-2031.00       0.43      0.42      0.43       109\n",
      "  43-4051.00       0.33      0.33      0.33        92\n",
      "  49-3023.02       0.44      0.41      0.42        58\n",
      "  49-9071.00       0.39      0.35      0.36        78\n",
      "  53-3032.00       0.46      0.29      0.36        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.42      0.39      0.40      3025\n",
      "weighted avg       0.45      0.45      0.45      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 42   8   5   8  15   6   3   4   3  11   0   1   2   9   1   6  11   3\n",
      "    3   3   3]\n",
      " [ 15  87  18   4  19   5   3   3  11   4   1   3   2   4   2   6   3   4\n",
      "    0   1   0]\n",
      " [  6  25  41   8   3   2   1   3   5   2   1   1   1   2   0   2   8   5\n",
      "    2   1   0]\n",
      " [  3   7   7  50  12   9   0   1   3   0   0   3   0   1   0   1   6   3\n",
      "    1   1   0]\n",
      " [ 14   9   6   8  66   3   4   7   9  10   0   8   4   3   2  11   1   5\n",
      "    1   0   2]\n",
      " [  3   2   0   6   8  26   1   8   2   5   0   1   1   2   1   4   1   0\n",
      "    0   1   0]\n",
      " [  1   5   1   0  14   4  21   7  12  16   3   5   1   5   1  12   0   0\n",
      "    1   1   0]\n",
      " [  7   6   1   7  10   0   5 147  12  18   0  23   5   2   0  11   1   3\n",
      "    1   4   0]\n",
      " [  3   4   0   4   8   2   6   6 151  28   6  20   4   3   1  14   1   6\n",
      "    1   2   0]\n",
      " [  9   3   3   2  10   1   5  18  42  84   3  35   4   3   1  16   0   2\n",
      "    2   2   1]\n",
      " [  0   3   1   3   2   0   0   1  22   2  11   0   1   0   0   1   0   1\n",
      "    0   0   1]\n",
      " [  1   2   6   0   5   5   6  14  19  39   1 142  16   1   2   4   1   1\n",
      "    2   3   0]\n",
      " [  3   6   2   1   2   2   1   7   8   8   1  13  19   2   0   4   4   5\n",
      "    0   1   0]\n",
      " [  3   3   2   2   7   0   1   0   2   1   0   4   2 246  13   1   0   4\n",
      "    1   4   1]\n",
      " [  3   1   1   0   2   0   1   2   0   0   0   0   1  41  15   1   0   1\n",
      "    0   0   1]\n",
      " [  5   2   2   0  10   0   4  15   7  10   0   6   1   3   0  81   0   1\n",
      "    1   0   0]\n",
      " [ 17   5   6   1   3   2   0   0   3   2   0   1   1   4   1   1  46   7\n",
      "    4   1   4]\n",
      " [  4   2   3   3   3   3   0   2   2   1   0   3   3  15   4   2   5  30\n",
      "    2   3   2]\n",
      " [  3   3   1   0   0   0   0   0   1   2   0   4   0   1   1   0   7   4\n",
      "   24   5   2]\n",
      " [  3   7   0   0   1   0   0   3   2   3   0   5   1   6   1   3   2   4\n",
      "    6  27   4]\n",
      " [  8   2   0   1   1   0   1   0   0   3   0   0   0   2   0   1   9   3\n",
      "    3  10  18]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='l1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.157s\n",
      "test time:  0.001s\n",
      "accuracy:   0.400\n",
      "dimensionality: 4229\n",
      "density: 0.019536\n",
      "top 10 keywords per class:\n",
      "11-1021.00: goods outbound models store payer qpm shopping cabin party honduras\n",
      "11-2021.00: raceway consumer stewardship alliances snacks capture art channel...\n",
      "11-2022.00: snr reagan economics sheraton intl prepaid smb broad specialitst ...\n",
      "11-3031.02: mc transactions sec recognition audit dealer fc accountant hours tax\n",
      "13-1111.00: acc acquistion jcid capability facets commissions accenture mba a...\n",
      "13-2051.00: nextlink fp budget alm provost fpa treasury cta sow cpic\n",
      "15-1121.00: jopes maritime gl order azeri ast appsw oversight linguist epic\n",
      "15-1122.00: ids isso fingerprinting fisma authorization soc malware splunk as...\n",
      "15-1132.00: android salesforce dwbi migration ui devops adobe software hot trust\n",
      "15-1133.00: ground spectrum payload satellite optical combat embedded dasd mk...\n",
      "15-1134.00: js web developer workers ability mvc ssbu react sharepoint drupal\n",
      "15-1142.00: voip iafnos lan academy vmware administrator datacenter engr sds ...\n",
      "15-1151.00: fires technical helpdesk vip desktop ending recording peer ssds d...\n",
      "29-1141.00: rehabilitation perioperative rcm clinical case therapy lpn therap...\n",
      "31-1014.00: nursing assistants certified adolescent rcis pbuse cv pca monitor...\n",
      "33-3021.06: elint biographic targeting wmd target osint intelligence imagery ...\n",
      "41-2031.00: toyota footwear shoes csa prestige apparel peppers cosmetics nex rdg\n",
      "43-4051.00: resort trained delinquency olde clerical gound leasing caregiver ...\n",
      "49-3023.02: shop diesel mechanic hwy automotive tire heavy body lube copier\n",
      "49-9071.00: roadway datapower installer ammonia espan ol vdot maintenance hva...\n",
      "53-3032.00: mailroom quadrant truck proposed lst cdl route weekly driver drivers\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.20      0.35      0.26       147\n",
      "  11-2021.00       0.50      0.36      0.42       195\n",
      "  11-2022.00       0.40      0.19      0.26       119\n",
      "  11-3031.02       0.53      0.39      0.45       108\n",
      "  13-1111.00       0.47      0.13      0.21       173\n",
      "  13-2051.00       0.55      0.08      0.14        72\n",
      "  15-1121.00       0.58      0.10      0.17       110\n",
      "  15-1122.00       0.40      0.61      0.48       263\n",
      "  15-1132.00       0.47      0.52      0.49       270\n",
      "  15-1133.00       0.38      0.30      0.33       246\n",
      "  15-1134.00       0.14      0.20      0.16        49\n",
      "  15-1142.00       0.58      0.55      0.57       270\n",
      "  15-1151.00       0.31      0.12      0.18        89\n",
      "  29-1141.00       0.73      0.81      0.77       297\n",
      "  31-1014.00       0.56      0.14      0.23        70\n",
      "  33-3021.06       0.60      0.34      0.43       148\n",
      "  41-2031.00       0.45      0.43      0.44       109\n",
      "  43-4051.00       0.18      0.27      0.22        92\n",
      "  49-3023.02       0.08      0.57      0.14        58\n",
      "  49-9071.00       0.51      0.26      0.34        78\n",
      "  53-3032.00       0.68      0.24      0.36        62\n",
      "\n",
      "    accuracy                           0.40      3025\n",
      "   macro avg       0.44      0.33      0.34      3025\n",
      "weighted avg       0.47      0.40      0.40      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 51   4   2   3   2   1   0   8   6   5   1   2   1   8   0   3  13   9\n",
      "   28   0   0]\n",
      " [ 33  70  12   2   4   0   1  11   8   1   4   4   0   2   0   3   8   5\n",
      "   27   0   0]\n",
      " [ 28  18  23   7   2   0   0   5   4   0   2   2   0   1   0   0   4   4\n",
      "   19   0   0]\n",
      " [ 14   4   3  42   2   0   0   8   3   0   2   3   0   1   0   1   6   5\n",
      "   14   0   0]\n",
      " [ 17   5   2   7  23   0   1  36  18   5   9   8   2   5   0   1   1  12\n",
      "   19   1   1]\n",
      " [  6   2   1   5   0   6   0  28   1   3   2   1   0   3   0   0   0   1\n",
      "   13   0   0]\n",
      " [  7   1   0   0   2   1  11  25  12   4  13   5   1   3   0   6   0   8\n",
      "   10   1   0]\n",
      " [  9   6   1   5   1   0   1 161  11  16   5  15   2   1   0   3   0   9\n",
      "   15   2   0]\n",
      " [  8   4   0   2   0   0   0  23 140  33   5  12   2   2   1   4   2   9\n",
      "   22   1   0]\n",
      " [ 15   3   4   1   2   1   0  25  47  73   7  26   6   2   0   7   0   9\n",
      "   17   0   1]\n",
      " [  2   5   1   1   0   0   0   0  22   3  10   0   1   0   0   0   0   2\n",
      "    1   0   1]\n",
      " [  7   0   2   0   3   1   2  20  13  28   2 149   5   0   1   0   2   9\n",
      "   23   3   0]\n",
      " [  6   0   0   0   1   0   1  12   3   7   2  10  11   2   0   3   0   9\n",
      "   22   0   0]\n",
      " [  5   1   0   2   2   0   0   2   4   0   0   3   0 240   3   0   3   3\n",
      "   26   3   0]\n",
      " [  4   0   1   0   1   0   0   1   1   1   0   1   0  39  10   1   0   1\n",
      "    9   0   0]\n",
      " [  9   3   0   0   1   0   1  39   2   9   6   7   2   1   0  50   0   6\n",
      "   12   0   0]\n",
      " [ 10   3   4   1   0   1   0   0   3   1   2   1   1   3   1   1  47   3\n",
      "   26   0   1]\n",
      " [  5   2   1   0   0   0   1   1   0   0   1   1   2   8   2   0   7  25\n",
      "   33   3   0]\n",
      " [  3   4   0   1   1   0   0   0   0   1   0   2   0   1   0   0   4   4\n",
      "   33   2   2]\n",
      " [  4   4   0   0   2   0   0   2   1   1   0   4   0   4   0   1   0   3\n",
      "   31  20   1]\n",
      " [  7   0   0   1   0   0   0   0   0   3   0   1   0   1   0   0   7   4\n",
      "   20   3  15]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
      "train time: 0.221s\n",
      "test time:  0.001s\n",
      "accuracy:   0.451\n",
      "dimensionality: 4229\n",
      "density: 0.146179\n",
      "top 10 keywords per class:\n",
      "11-1021.00: attorney initiative bench outbound shopping qpm store goods party...\n",
      "11-2021.00: campaign product iot alliances hhonors art channel capture brand ...\n",
      "11-2022.00: immediately intl major account pharmaceutical craft smb od prime ...\n",
      "11-3031.02: banker needs accounting sec audit recognition fc accountant hours...\n",
      "13-1111.00: facets acc acquistion change mlt effectiveness ocm adoption accen...\n",
      "13-2051.00: investments economic budget isrm cont fp alm fpa treasury cpic\n",
      "15-1121.00: fighter enabled order gl maritime strike mss appsw linguist epic\n",
      "15-1122.00: isso cnd fingerprinting ids malware soc splunk authorization assu...\n",
      "15-1132.00: developer adobe trust netsuite hot android salesforce ui software...\n",
      "15-1133.00: simulations satellite payload ground spacecraft optical spectrum ...\n",
      "15-1134.00: workers jbpm aem sofware rational brava osisoft mvc drupal sharep...\n",
      "15-1142.00: unix voip lan iafnos wan engr sds vmware administrator network\n",
      "15-1151.00: css disciplinary game recording printer arboretum passive vip ssd...\n",
      "29-1141.00: appeals hospital rehabilitation case rcm clinical lpn therapist n...\n",
      "31-1014.00: aide pca cardiology sleep cv academic nursing certified cna monitor\n",
      "33-3021.06: watchlist collection elint target citp wmd targeting imagery sour...\n",
      "41-2031.00: supv sprint toyota shoes footwear prestige apparel cosmetics reta...\n",
      "43-4051.00: activities olde mtf rws promotions delinquency caregiver clerical...\n",
      "49-3023.02: exhaust shop diesel mechanic ase automotive heavy body tire lube\n",
      "49-9071.00: apartment welder apartments datapower roadway ammonia ol espan ma...\n",
      "53-3032.00: super motor archery armed lst loom truck route drivers driver\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.27      0.22      0.24       147\n",
      "  11-2021.00       0.45      0.41      0.43       195\n",
      "  11-2022.00       0.41      0.31      0.35       119\n",
      "  11-3031.02       0.44      0.50      0.47       108\n",
      "  13-1111.00       0.35      0.28      0.31       173\n",
      "  13-2051.00       0.36      0.39      0.38        72\n",
      "  15-1121.00       0.28      0.22      0.25       110\n",
      "  15-1122.00       0.57      0.57      0.57       263\n",
      "  15-1132.00       0.41      0.63      0.50       270\n",
      "  15-1133.00       0.37      0.19      0.25       246\n",
      "  15-1134.00       0.42      0.22      0.29        49\n",
      "  15-1142.00       0.50      0.61      0.55       270\n",
      "  15-1151.00       0.25      0.15      0.19        89\n",
      "  29-1141.00       0.67      0.86      0.75       297\n",
      "  31-1014.00       0.39      0.19      0.25        70\n",
      "  33-3021.06       0.47      0.58      0.52       148\n",
      "  41-2031.00       0.39      0.52      0.45       109\n",
      "  43-4051.00       0.33      0.25      0.28        92\n",
      "  49-3023.02       0.35      0.40      0.37        58\n",
      "  49-9071.00       0.34      0.36      0.35        78\n",
      "  53-3032.00       0.51      0.31      0.38        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.41      0.39      0.39      3025\n",
      "weighted avg       0.44      0.45      0.43      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 33  12   2  11  12   5   5   6   8   7   1   3   1  13   2   4  15   2\n",
      "    3   1   1]\n",
      " [ 12  80  20   7  12   4   2   8  15   1   1   2   0   3   4   6   8   6\n",
      "    1   3   0]\n",
      " [  4  26  37  11   4   4   1   3   6   1   1   2   0   2   0   3   7   2\n",
      "    3   2   0]\n",
      " [  3   3   3  54   6   8   2   5   4   0   0   2   2   2   0   2   7   4\n",
      "    0   1   0]\n",
      " [ 13   9   4   9  49   6   7   5  18   7   0  13   3   7   0  10   3   5\n",
      "    1   1   3]\n",
      " [  2   1   1   6   6  28   6   7   3   3   0   1   0   2   1   4   0   0\n",
      "    0   1   0]\n",
      " [  2   2   1   0  10   4  24   5  13  13   3   8   0   4   1  13   1   1\n",
      "    0   4   1]\n",
      " [  3   7   3   3   4   1   6 150  18  12   0  22   2   2   0  16   2   3\n",
      "    4   5   0]\n",
      " [  3   5   0   4   6   2   4  10 171   5   4  22   4   5   1  12   5   2\n",
      "    2   2   1]\n",
      " [  7   6   4   0   6   3   6  21  68  46   3  46   2   4   0  14   1   1\n",
      "    2   5   1]\n",
      " [  0   3   2   1   1   0   0   0  25   1  11   0   1   0   0   1   1   1\n",
      "    0   0   1]\n",
      " [  3   2   2   1   3   4   7  13  36   9   1 164   9   2   1   3   1   2\n",
      "    4   3   0]\n",
      " [  4   1   1   3   4   3   1   7   7   4   1  19  13   6   0   3   4   2\n",
      "    2   3   1]\n",
      " [  2   2   1   3   4   0   2   2   2   0   0   5   3 255   6   1   1   3\n",
      "    1   4   0]\n",
      " [  4   0   1   0   0   0   1   2   0   0   0   1   1  43  13   1   0   2\n",
      "    0   0   1]\n",
      " [  3   5   0   2   6   1   4  14   9   7   0   5   3   2   0  86   0   1\n",
      "    0   0   0]\n",
      " [ 13   3   6   2   3   1   1   0   3   2   0   0   1   3   1   1  57   2\n",
      "    6   2   2]\n",
      " [  1   4   2   3   2   2   0   2   2   1   0   1   5  15   3   3  14  23\n",
      "    4   4   1]\n",
      " [  1   4   0   3   0   1   0   0   1   2   0   4   1   1   0   0   5   2\n",
      "   23   7   3]\n",
      " [  5   3   0   0   2   0   2   4   5   4   0   6   0   6   0   0   2   3\n",
      "    6  28   2]\n",
      " [  5   1   0   1   0   0   4   0   0   1   0   3   0   2   0   1  12   3\n",
      "    3   7  19]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid()\n",
      "train time: 0.016s\n",
      "test time:  0.001s\n",
      "accuracy:   0.407\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.20      0.44      0.27       147\n",
      "  11-2021.00       0.45      0.39      0.42       195\n",
      "  11-2022.00       0.45      0.34      0.39       119\n",
      "  11-3031.02       0.43      0.40      0.42       108\n",
      "  13-1111.00       0.39      0.31      0.35       173\n",
      "  13-2051.00       0.33      0.33      0.33        72\n",
      "  15-1121.00       0.32      0.31      0.31       110\n",
      "  15-1122.00       0.70      0.47      0.56       263\n",
      "  15-1132.00       0.62      0.32      0.42       270\n",
      "  15-1133.00       0.33      0.35      0.34       246\n",
      "  15-1134.00       0.26      0.47      0.34        49\n",
      "  15-1142.00       0.70      0.40      0.51       270\n",
      "  15-1151.00       0.15      0.36      0.21        89\n",
      "  29-1141.00       0.85      0.62      0.72       297\n",
      "  31-1014.00       0.26      0.33      0.29        70\n",
      "  33-3021.06       0.38      0.52      0.44       148\n",
      "  41-2031.00       0.39      0.46      0.42       109\n",
      "  43-4051.00       0.28      0.41      0.33        92\n",
      "  49-3023.02       0.22      0.45      0.29        58\n",
      "  49-9071.00       0.40      0.29      0.34        78\n",
      "  53-3032.00       0.35      0.24      0.29        62\n",
      "\n",
      "    accuracy                           0.41      3025\n",
      "   macro avg       0.40      0.39      0.38      3025\n",
      "weighted avg       0.48      0.41      0.43      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 64  16   4   3   4   2   4   0   1   3   0   0  11   3   3   3  12   8\n",
      "    2   2   2]\n",
      " [ 31  76  22  11  11   3   4   2   0   2   2   0   7   0   1  11   7   4\n",
      "    0   1   0]\n",
      " [ 21  16  41   8   3   2   0   2   0   0   0   1   3   0   1   2  14   2\n",
      "    2   0   1]\n",
      " [ 15   6   7  43   6  12   3   1   0   0   0   1   2   0   0   3   6   2\n",
      "    0   0   1]\n",
      " [ 21   7   1  10  54  11  13   3   1   6   3   2  14   0   1  10   5   5\n",
      "    2   1   3]\n",
      " [  6   1   0   5   7  24   4   4   0   1   1   1   6   0   1   6   1   3\n",
      "    0   0   1]\n",
      " [ 10   3   2   0   9   3  34   2   2   4   3   3   8   0   3  17   0   4\n",
      "    2   0   1]\n",
      " [ 15   4   0   5   2   1   3 123   6  27   2   7  17   0   2  32   2   4\n",
      "    7   1   3]\n",
      " [ 13  10   0   2  12   3   6   3  86  49  40   5  12   1   2  10   2   5\n",
      "    7   1   1]\n",
      " [ 19   2   2   3   8   1  16   7  26  86  10  14  25   1   1  16   0   2\n",
      "    5   1   1]\n",
      " [  3   3   0   0   1   0   1   0   6   6  23   0   2   0   0   2   0   1\n",
      "    0   0   1]\n",
      " [ 10   0   0   1   2   1   6  11   4  56   3 109  31   0   2  10   2   5\n",
      "   13   3   1]\n",
      " [  8   2   1   1   1   3   1   6   1   6   1   5  32   0   0   3   2   7\n",
      "    9   0   0]\n",
      " [ 23   7   3   0   2   0   3   2   1   0   0   2   6 184  33   1   2  10\n",
      "   10   7   1]\n",
      " [  7   0   1   0   1   0   1   1   0   0   0   0   5  22  23   0   0   2\n",
      "    5   2   0]\n",
      " [ 18   1   0   1   8   2   6   7   4   5   0   2  13   1   0  77   0   1\n",
      "    1   0   1]\n",
      " [ 13   3   5   4   3   1   0   0   0   0   0   0   4   1   2   0  50  14\n",
      "    6   1   2]\n",
      " [ 11   4   0   0   4   3   0   1   0   0   0   0   4   1   8   0  10  38\n",
      "    3   2   3]\n",
      " [  4   4   1   0   0   0   0   0   0   1   0   1   4   0   2   0   6   2\n",
      "   26   5   2]\n",
      " [  6   3   1   1   0   0   1   0   0   4   0   2   9   2   0   0   1   8\n",
      "   14  23   3]\n",
      " [  8   0   0   1   0   0   1   0   0   1   0   1   2   0   4   0   6  10\n",
      "    6   7  15]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01)\n",
      "train time: 0.034s\n",
      "test time:  0.001s\n",
      "accuracy:   0.453\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.26      0.25      0.26       147\n",
      "  11-2021.00       0.41      0.43      0.42       195\n",
      "  11-2022.00       0.39      0.33      0.36       119\n",
      "  11-3031.02       0.46      0.49      0.48       108\n",
      "  13-1111.00       0.30      0.37      0.33       173\n",
      "  13-2051.00       0.42      0.28      0.33        72\n",
      "  15-1121.00       0.35      0.22      0.27       110\n",
      "  15-1122.00       0.55      0.58      0.56       263\n",
      "  15-1132.00       0.46      0.57      0.51       270\n",
      "  15-1133.00       0.35      0.31      0.33       246\n",
      "  15-1134.00       0.38      0.18      0.25        49\n",
      "  15-1142.00       0.54      0.59      0.56       270\n",
      "  15-1151.00       0.32      0.25      0.28        89\n",
      "  29-1141.00       0.69      0.81      0.74       297\n",
      "  31-1014.00       0.35      0.20      0.25        70\n",
      "  33-3021.06       0.52      0.53      0.53       148\n",
      "  41-2031.00       0.44      0.47      0.45       109\n",
      "  43-4051.00       0.30      0.35      0.32        92\n",
      "  49-3023.02       0.38      0.40      0.39        58\n",
      "  49-9071.00       0.42      0.36      0.39        78\n",
      "  53-3032.00       0.40      0.23      0.29        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.41      0.39      0.39      3025\n",
      "weighted avg       0.44      0.45      0.44      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 37  15   4   4  15   3   2   5   8  11   0   2   0  13   1   5  11   5\n",
      "    3   2   1]\n",
      " [ 14  83  22  10  19   2   2   4  14   5   1   2   2   2   1   5   1   5\n",
      "    0   1   0]\n",
      " [  2  29  39  10   6   1   1   3   5   1   0   0   1   2   0   2   6   7\n",
      "    3   1   0]\n",
      " [  6  10   3  53  15   4   0   3   1   0   0   1   1   0   0   0   6   4\n",
      "    0   1   0]\n",
      " [ 11  14   5   7  64   5   6   4  12  10   0  10   2   4   1   5   3   6\n",
      "    2   0   2]\n",
      " [  5   0   1  10  11  20   2   6   2   6   0   1   0   2   1   2   0   2\n",
      "    1   0   0]\n",
      " [  2   4   1   0  11   4  24   6  14  17   1   5   1   4   1  13   0   0\n",
      "    0   2   0]\n",
      " [  5   5   2   4  10   0   5 152  20  14   0  18   8   1   0  12   1   2\n",
      "    3   1   0]\n",
      " [  1   5   1   0  11   2   6  12 153  22   9  21   5   5   0   8   1   3\n",
      "    2   1   2]\n",
      " [  7   2   3   3  12   1   7  23  41  76   3  47   3   3   1   9   0   1\n",
      "    1   2   1]\n",
      " [  0   3   1   1   2   0   0   2  22   2   9   4   0   0   0   0   0   1\n",
      "    0   0   2]\n",
      " [  2   3   3   0   3   3   4  17  22  27   0 158  14   2   1   2   2   1\n",
      "    3   3   0]\n",
      " [  4   4   1   3   4   2   1   8   6   6   1  11  22   4   0   2   3   4\n",
      "    0   2   1]\n",
      " [  4   2   2   3   6   0   3   0   2   0   0   0   3 240  14   1   3   9\n",
      "    1   4   0]\n",
      " [  3   1   1   0   1   0   1   2   0   1   0   0   1  39  14   0   1   3\n",
      "    1   1   0]\n",
      " [  4   5   1   0  14   0   4  18   6   9   0   5   1   1   0  79   0   0\n",
      "    1   0   0]\n",
      " [ 16   3   7   1   2   0   0   3   2   2   0   0   2   3   1   1  51   7\n",
      "    4   1   3]\n",
      " [  4   5   1   3   5   1   0   3   1   1   0   2   1  15   4   1   8  32\n",
      "    2   2   1]\n",
      " [  4   2   1   1   0   0   0   1   1   1   0   4   1   2   0   0   8   4\n",
      "   23   4   1]\n",
      " [  5   6   0   0   1   0   1   4   2   3   0   3   0   6   0   3   0   3\n",
      "    6  28   7]\n",
      " [  7   0   0   1   0   0   0   0   0   3   0   0   0   2   0   1  12   6\n",
      "    5  11  14]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01)\n",
      "train time: 0.032s\n",
      "test time:  0.003s\n",
      "accuracy:   0.457\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.23      0.27      0.25       147\n",
      "  11-2021.00       0.43      0.44      0.43       195\n",
      "  11-2022.00       0.40      0.39      0.40       119\n",
      "  11-3031.02       0.44      0.44      0.44       108\n",
      "  13-1111.00       0.33      0.36      0.35       173\n",
      "  13-2051.00       0.35      0.32      0.33        72\n",
      "  15-1121.00       0.32      0.28      0.30       110\n",
      "  15-1122.00       0.61      0.57      0.59       263\n",
      "  15-1132.00       0.50      0.50      0.50       270\n",
      "  15-1133.00       0.37      0.30      0.33       246\n",
      "  15-1134.00       0.29      0.31      0.30        49\n",
      "  15-1142.00       0.56      0.56      0.56       270\n",
      "  15-1151.00       0.26      0.28      0.27        89\n",
      "  29-1141.00       0.75      0.78      0.76       297\n",
      "  31-1014.00       0.37      0.29      0.32        70\n",
      "  33-3021.06       0.52      0.59      0.55       148\n",
      "  41-2031.00       0.46      0.49      0.47       109\n",
      "  43-4051.00       0.30      0.37      0.33        92\n",
      "  49-3023.02       0.37      0.45      0.40        58\n",
      "  49-9071.00       0.41      0.40      0.40        78\n",
      "  53-3032.00       0.37      0.24      0.29        62\n",
      "\n",
      "    accuracy                           0.46      3025\n",
      "   macro avg       0.41      0.41      0.41      3025\n",
      "weighted avg       0.46      0.46      0.46      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 40  16   8   5  14   4   3   3   5   7   0   2   1  10   1   4  10   6\n",
      "    3   2   3]\n",
      " [ 19  85  25   7  17   5   3   3  10   1   2   1   2   1   2   5   1   5\n",
      "    0   1   0]\n",
      " [  5  22  47  10   3   2   1   3   1   1   1   0   1   2   0   1   7   8\n",
      "    2   2   0]\n",
      " [  9   6   4  48  12  10   0   2   1   0   0   1   3   0   0   1   5   4\n",
      "    0   1   1]\n",
      " [ 13  15   4   7  63   9   9   4   6   6   0   7   8   3   0   7   3   5\n",
      "    2   0   2]\n",
      " [  5   1   1   7  11  23   2   5   2   3   0   1   2   2   1   4   0   1\n",
      "    1   0   0]\n",
      " [  5   4   2   2  10   2  31   5  10  13   2   2   3   2   1  12   0   1\n",
      "    0   3   0]\n",
      " [  5   5   3   5   7   1   7 149  16  15   1  17   9   1   0  14   1   2\n",
      "    4   1   0]\n",
      " [  4   5   1   1   9   2   8   9 135  27  23  19   5   3   0   8   1   4\n",
      "    3   1   2]\n",
      " [  9   4   3   3  13   2  10  18  34  73   6  44   3   1   1  15   0   1\n",
      "    1   4   1]\n",
      " [  0   3   1   1   3   0   0   2  17   2  15   3   1   0   0   0   0   0\n",
      "    0   0   1]\n",
      " [  1   4   2   0   5   2   7  17  17  31   1 150  19   1   0   3   2   1\n",
      "    3   4   0]\n",
      " [  4   4   1   2   3   3   3   6   5   6   1   8  25   2   0   3   2   5\n",
      "    3   2   1]\n",
      " [  8   3   3   2   3   0   4   0   2   0   0   0   3 231  19   1   2  11\n",
      "    1   4   0]\n",
      " [  4   0   1   1   1   0   2   1   0   0   0   0   1  33  20   0   1   3\n",
      "    1   1   0]\n",
      " [  5   7   2   0  11   0   6  11   4   4   0   5   2   1   0  88   0   1\n",
      "    1   0   0]\n",
      " [ 16   3   8   1   2   0   0   2   2   0   0   0   1   3   1   1  53   7\n",
      "    5   1   3]\n",
      " [  6   5   1   3   4   1   0   1   0   0   0   3   2   8   6   0   8  34\n",
      "    3   2   5]\n",
      " [  4   2   0   1   0   0   0   1   0   1   0   1   3   1   0   0   8   5\n",
      "   26   4   1]\n",
      " [  5   5   1   0   0   0   1   2   2   3   0   2   2   2   1   2   0   6\n",
      "    7  31   6]\n",
      " [  5   0   0   2   0   0   0   0   0   3   0   0   0   2   1   1  11   5\n",
      "    5  12  15]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1)\n",
      "train time: 0.032s\n",
      "test time:  0.001s\n",
      "accuracy:   0.436\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.25      0.18      0.21       147\n",
      "  11-2021.00       0.44      0.42      0.43       195\n",
      "  11-2022.00       0.36      0.30      0.33       119\n",
      "  11-3031.02       0.42      0.46      0.44       108\n",
      "  13-1111.00       0.32      0.33      0.32       173\n",
      "  13-2051.00       0.34      0.33      0.34        72\n",
      "  15-1121.00       0.27      0.18      0.22       110\n",
      "  15-1122.00       0.55      0.56      0.55       263\n",
      "  15-1132.00       0.47      0.56      0.51       270\n",
      "  15-1133.00       0.32      0.23      0.27       246\n",
      "  15-1134.00       0.40      0.20      0.27        49\n",
      "  15-1142.00       0.51      0.60      0.55       270\n",
      "  15-1151.00       0.30      0.21      0.25        89\n",
      "  29-1141.00       0.64      0.85      0.73       297\n",
      "  31-1014.00       0.27      0.14      0.19        70\n",
      "  33-3021.06       0.44      0.51      0.47       148\n",
      "  41-2031.00       0.38      0.47      0.42       109\n",
      "  43-4051.00       0.28      0.25      0.26        92\n",
      "  49-3023.02       0.34      0.45      0.39        58\n",
      "  49-9071.00       0.32      0.32      0.32        78\n",
      "  53-3032.00       0.36      0.27      0.31        62\n",
      "\n",
      "    accuracy                           0.44      3025\n",
      "   macro avg       0.38      0.37      0.37      3025\n",
      "weighted avg       0.42      0.44      0.42      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 27  12   3   7  11   6   3   5   8   8   1   5   0  14   1   6  14   4\n",
      "    5   5   2]\n",
      " [ 10  82  25   8  13   4   5   4  14   3   1   2   2   5   0   5   6   3\n",
      "    0   2   1]\n",
      " [  5  22  36  10   5   3   2   3   5   1   1   1   1   2   0   2   9   5\n",
      "    3   3   0]\n",
      " [  1  10   5  50  10   9   0   4   2   0   0   3   1   1   0   1   6   4\n",
      "    0   1   0]\n",
      " [  8  11   4  11  57   5   5   7   9   8   0   8   5  12   1   9   3   4\n",
      "    4   0   2]\n",
      " [  2   1   1   6   8  24   1   6   2   5   0   2   1   3   1   3   2   2\n",
      "    1   0   1]\n",
      " [  1   3   1   0  12   3  20   6  10  16   2   8   0   5   2  14   0   1\n",
      "    1   3   2]\n",
      " [  4   6   2   6   6   1   7 146  17  11   0  21   6   3   1  12   1   2\n",
      "    5   3   3]\n",
      " [  3   6   1   4   8   2   5  15 151  16   4  20   4   5   1  13   4   2\n",
      "    1   3   2]\n",
      " [ 11   3   4   4  11   2   7  22  39  57   2  52   6   4   1  12   2   1\n",
      "    1   4   1]\n",
      " [  0   3   1   1   2   0   0   2  24   2  10   0   0   0   0   1   0   1\n",
      "    0   0   2]\n",
      " [  2   3   5   1   3   4   7  11  17  23   1 162  12   2   2   5   2   2\n",
      "    3   3   0]\n",
      " [  3   3   1   3   4   2   1   7   6   5   2  11  19   6   0   3   4   6\n",
      "    0   2   1]\n",
      " [  2   2   0   2   7   0   3   1   2   1   0   3   1 252   9   1   1   3\n",
      "    2   4   1]\n",
      " [  4   1   1   0   1   0   1   1   0   0   0   1   0  44  10   2   0   2\n",
      "    0   1   1]\n",
      " [  2   2   1   1  12   1   4  18   7  11   1   8   1   1   0  75   1   0\n",
      "    2   0   0]\n",
      " [  8   3   6   1   3   1   1   1   2   2   0   1   3   4   2   1  51   6\n",
      "    8   2   3]\n",
      " [  3   4   3   3   5   4   0   2   1   0   0   1   1  19   4   2  10  23\n",
      "    4   2   1]\n",
      " [  2   4   0   1   0   0   0   1   1   2   0   3   0   2   1   0   6   3\n",
      "   26   4   2]\n",
      " [  4   7   0   0   1   0   0   4   2   3   0   5   0   6   0   2   3   4\n",
      "    7  25   5]\n",
      " [  7   0   0   1   0   0   2   0   1   2   0   1   0   2   1   0  11   4\n",
      "    3  10  17]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
      "                                                     tol=0.001))),\n",
      "                ('classification', LinearSVC())])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.058s\n",
      "test time:  0.002s\n",
      "accuracy:   0.455\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  11-1021.00       0.25      0.27      0.26       147\n",
      "  11-2021.00       0.43      0.43      0.43       195\n",
      "  11-2022.00       0.39      0.35      0.37       119\n",
      "  11-3031.02       0.47      0.45      0.46       108\n",
      "  13-1111.00       0.32      0.35      0.34       173\n",
      "  13-2051.00       0.40      0.38      0.39        72\n",
      "  15-1121.00       0.32      0.20      0.25       110\n",
      "  15-1122.00       0.60      0.57      0.58       263\n",
      "  15-1132.00       0.49      0.56      0.52       270\n",
      "  15-1133.00       0.32      0.31      0.32       246\n",
      "  15-1134.00       0.41      0.27      0.32        49\n",
      "  15-1142.00       0.52      0.54      0.53       270\n",
      "  15-1151.00       0.27      0.22      0.25        89\n",
      "  29-1141.00       0.70      0.82      0.76       297\n",
      "  31-1014.00       0.31      0.21      0.25        70\n",
      "  33-3021.06       0.49      0.59      0.54       148\n",
      "  41-2031.00       0.45      0.45      0.45       109\n",
      "  43-4051.00       0.35      0.35      0.35        92\n",
      "  49-3023.02       0.39      0.38      0.38        58\n",
      "  49-9071.00       0.38      0.35      0.36        78\n",
      "  53-3032.00       0.44      0.32      0.37        62\n",
      "\n",
      "    accuracy                           0.45      3025\n",
      "   macro avg       0.41      0.40      0.40      3025\n",
      "weighted avg       0.45      0.45      0.45      3025\n",
      "\n",
      "confusion matrix:\n",
      "[[ 40  13   5   7  13   5   3   4   5  12   0   1   1   9   1   6  11   4\n",
      "    1   4   2]\n",
      " [ 14  83  19   4  17   6   3   5  12   6   1   2   2   3   3   4   4   4\n",
      "    0   3   0]\n",
      " [  7  24  42   8   3   3   1   3   4   2   1   2   1   3   0   2   6   4\n",
      "    2   1   0]\n",
      " [  7   6   9  49  12   8   0   0   3   0   0   2   2   0   0   0   5   3\n",
      "    1   1   0]\n",
      " [ 17  10   5   8  61   4   7   7   8   8   1   8   4   5   1   7   1   7\n",
      "    2   0   2]\n",
      " [  3   1   0   6   8  27   1   7   2   5   0   1   1   2   1   4   1   0\n",
      "    1   0   1]\n",
      " [  3   3   1   0  16   4  22   6  10  16   2   5   1   4   2  12   0   0\n",
      "    2   1   0]\n",
      " [  8   6   1   7  11   0   4 149  11  18   0  22   4   1   0  11   2   3\n",
      "    1   4   0]\n",
      " [  4   6   0   3   9   2   6   8 150  27   8  20   4   2   1  11   1   6\n",
      "    1   1   0]\n",
      " [  9   3   3   3  10   1   8  17  42  76   3  40   4   3   1  17   1   0\n",
      "    2   2   1]\n",
      " [  0   4   1   0   2   0   0   1  21   2  13   0   1   0   0   1   0   1\n",
      "    0   0   2]\n",
      " [  1   3   4   0   4   5   6  13  19  36   1 146  16   1   1   5   1   2\n",
      "    2   3   1]\n",
      " [  3   6   2   2   4   2   1   7   7   7   1  11  20   2   0   4   4   2\n",
      "    2   1   1]\n",
      " [  4   3   2   2   4   0   2   0   2   2   0   3   3 244  14   1   1   5\n",
      "    1   3   1]\n",
      " [  3   1   1   0   2   0   1   2   0   0   0   0   1  41  15   0   0   2\n",
      "    0   0   1]\n",
      " [  4   2   1   0   9   0   3  14   6   9   0   7   1   3   0  88   0   0\n",
      "    0   1   0]\n",
      " [ 16   5   7   1   2   0   0   0   2   2   0   1   2   3   1   1  49   7\n",
      "    5   2   3]\n",
      " [  5   3   2   2   4   1   0   2   1   1   1   3   2  12   5   2   6  32\n",
      "    2   2   4]\n",
      " [  4   3   1   1   0   0   0   0   1   2   0   4   1   1   1   0   6   4\n",
      "   22   5   2]\n",
      " [  4   4   2   0   0   0   0   3   3   3   0   4   2   7   1   1   2   4\n",
      "    7  27   4]\n",
      " [  7   2   0   2   0   0   0   0   0   2   0   1   0   3   0   1   9   2\n",
      "    3  10  20]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "    (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "    (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "    (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "    (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "    (RandomForestClassifier(), \"Random forest\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print(\"=\" * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(\n",
    "    benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=\"elasticnet\"))\n",
    ")\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print(\"=\" * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print(\"=\" * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=0.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=0.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=0.1)))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(\n",
    "    benchmark(\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\n",
    "                    \"feature_selection\",\n",
    "                    SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "                ),\n",
    "                (\"classification\", LinearSVC(penalty=\"l2\")),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add plots\n",
    "The bar plot indicates the accuracy, training time (normalized) and test time\n",
    "(normalized) of each classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, 0.2, label=\"score\", color=\"navy\")\n",
    "plt.barh(indices + 0.3, training_time, 0.2, label=\"training time\", color=\"c\")\n",
    "plt.barh(indices + 0.6, test_time, 0.2, label=\"test time\", color=\"darkorange\")\n",
    "plt.yticks(())\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplots_adjust(left=0.25)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(bottom=0.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-0.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
